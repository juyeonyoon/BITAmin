{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54bc000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5cf8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Electronics_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f67e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af35f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_outlier(df=None, column=None, weight=1.5) :\n",
    "    quantile_25 = np.percentile(df[column].values, 25)\n",
    "    quantile_75 = np.percentile(df[column].values, 75)\n",
    "\n",
    "    IQR = quantile_75 - quantile_25\n",
    "    IQR_weight = IQR*weight\n",
    "\n",
    "    lowest = quantile_25 - IQR_weight\n",
    "    highest = quantile_75 + IQR_weight\n",
    "\n",
    "    outlier_idx = df[column][ (df[column] < lowest) | (df[column] > highest) ].index\n",
    "    return outlier_idx\n",
    "\n",
    "def bye_outlier(df=None, column=None, weight=1.5) :\n",
    "    outlier_idx = hello_outlier(df=df, column=column, weight=1.5)\n",
    "    df.drop(outlier_idx, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3d8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['dual','4G','3G','ts','wifi','blue'], inplace = True, axis=1)\n",
    "bye_outlier(df=df, column='front_c',weight=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38f9cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "ss = StandardScaler()\n",
    "scaled_X_standard = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X_standard, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "204ba54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier():  0.7987\n",
      "GaussianNB():  0.7852\n",
      "RandomForestClassifier():  0.8859\n",
      "AdaBoostClassifier():  0.5470\n",
      "GradientBoostingClassifier():  0.9060\n",
      "[18:56:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "              subsample=1, tree_method='exact', validate_parameters=1,\n",
      "              verbosity=None):  0.9195\n",
      "LGBMClassifier():  0.9228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "GNB = GaussianNB()\n",
    "rf = RandomForestClassifier()\n",
    "ada = AdaBoostClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "xgb = XGBClassifier()\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "for model in [tree, GNB, rf, ada, gb, xgb, lgbm]:\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_model = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred_model)\n",
    "    \n",
    "    print('{0}: {1: .4f}'.format(model, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ade87e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8791946308724832"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adaboost\n",
    "\n",
    "tree_model = DecisionTreeClassifier(max_depth=5)\n",
    "ada = AdaBoostClassifier(base_estimator=tree_model, n_estimators=50,random_state=0)\n",
    "ada.fit(X_train, y_train)\n",
    "pred_ada = ada.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d3f479f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 12, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 300}\n",
      "0.8556045908296204\n"
     ]
    }
   ],
   "source": [
    "# randomForest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_estimators':[300],\n",
    "         'max_depth' : [8,10,12],\n",
    "         'min_samples_leaf':[2,4,6],\n",
    "         'min_samples_split':[4,6,8]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "grid = GridSearchCV(rf, param_grid = params, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5654e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657718120805369"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300, max_depth = 10, min_samples_leaf = 2,\n",
    "                           min_samples_split=8, random_state=30)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0ee423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.8715286785855282\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boost\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100,500],\n",
    "    'learning_rate':[0.05, 0.1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(gb, param_grid = params, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbd13eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.889261744966443\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.1)\n",
    "gb.fit(X_train, y_train)\n",
    "pred_gb = gb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_gb)\n",
    "\n",
    "print('정확도: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca67b07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:44:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'learning_rate': 0.3, 'n_estimators': 100}\n",
      "0.8841323106423777\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100,500,600],\n",
    "    'learning_rate':[0.05,0.1,0.3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(xgb, param_grid = params, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db23fb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:45:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "정확도:  0.9026845637583892\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(grid.best_params_, max_depth=6)\n",
    "xgb.fit(X_train, y_train)\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_xgb)\n",
    "\n",
    "print('정확도: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54893100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.8749055326828719\n"
     ]
    }
   ],
   "source": [
    "#ligthgbm\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100,500],\n",
    "    'learning_rate':[0.01,0.05,0.1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(lgbm, param_grid = params, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3257400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.9228187919463087\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "pred_lgbm = grid.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_lgbm)\n",
    "\n",
    "print('정확도: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70699978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:46:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "정확도:  0.9060402684563759\n"
     ]
    }
   ],
   "source": [
    "#Voting\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_s = VotingClassifier(estimators=[('RF',rf), ('XGB',xgb),('LGBM',lgbm),('GB',gb)], voting='soft')\n",
    "\n",
    "voting_s.fit(X_train, y_train)\n",
    "pred_s = voting_s.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred_s)\n",
    "\n",
    "print('정확도: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d98870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  pd.read_csv('Electronics_testx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6621becb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BP</th>\n",
       "      <th>blue</th>\n",
       "      <th>c_speed</th>\n",
       "      <th>dual</th>\n",
       "      <th>front_c</th>\n",
       "      <th>4G</th>\n",
       "      <th>m_int</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>m_wt</th>\n",
       "      <th>...</th>\n",
       "      <th>prim_c</th>\n",
       "      <th>px_h</th>\n",
       "      <th>px_w</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_t</th>\n",
       "      <th>3G</th>\n",
       "      <th>ts</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1225</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1567</td>\n",
       "      <td>2423</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1399</td>\n",
       "      <td>1684</td>\n",
       "      <td>1658</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1186</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.4</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>584</td>\n",
       "      <td>2361</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>157</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>643</td>\n",
       "      <td>790</td>\n",
       "      <td>1380</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1731</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>809</td>\n",
       "      <td>1988</td>\n",
       "      <td>3892</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    BP  blue  c_speed  dual  front_c  4G  m_int  m_dep  m_wt  \\\n",
       "0           0  1225     0      0.7     1        6   0     60    0.1   107   \n",
       "1           1  1970     1      0.5     1        0   1     15    1.0   132   \n",
       "2           2  1186     1      0.5     1        2   0     21    0.4   160   \n",
       "3           3  1762     0      0.7     0        7   0     60    0.1   157   \n",
       "4           4  1731     1      1.4     1        4   1      4    0.5   163   \n",
       "\n",
       "   ...  prim_c  px_h  px_w   ram  sc_h  sc_w  talk_t  3G  ts  wifi  \n",
       "0  ...      15    10  1567  2423    17    11       6   1   0     0  \n",
       "1  ...       0  1399  1684  1658    15     9      20   1   1     1  \n",
       "2  ...       4    68   584  2361    17     8       7   1   0     0  \n",
       "3  ...      10   643   790  1380    14     5      14   1   0     0  \n",
       "4  ...      18   809  1988  3892     5     1       4   1   1     1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55366e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64f70476",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['dual','4G','3G','ts','wifi','blue'], inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33feaee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BP</th>\n",
       "      <th>c_speed</th>\n",
       "      <th>front_c</th>\n",
       "      <th>m_int</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>m_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>prim_c</th>\n",
       "      <th>px_h</th>\n",
       "      <th>px_w</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1225</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1567</td>\n",
       "      <td>2423</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1399</td>\n",
       "      <td>1684</td>\n",
       "      <td>1658</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1186</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.4</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>584</td>\n",
       "      <td>2361</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1762</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>643</td>\n",
       "      <td>790</td>\n",
       "      <td>1380</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1731</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>163</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>809</td>\n",
       "      <td>1988</td>\n",
       "      <td>3892</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BP  c_speed  front_c  m_int  m_dep  m_wt  n_cores  prim_c  px_h  px_w  \\\n",
       "0  1225      0.7        6     60    0.1   107        2      15    10  1567   \n",
       "1  1970      0.5        0     15    1.0   132        2       0  1399  1684   \n",
       "2  1186      0.5        2     21    0.4   160        8       4    68   584   \n",
       "3  1762      0.7        7     60    0.1   157        4      10   643   790   \n",
       "4  1731      1.4        4      4    0.5   163        6      18   809  1988   \n",
       "\n",
       "    ram  sc_h  sc_w  talk_t  \n",
       "0  2423    17    11       6  \n",
       "1  1658    15     9      20  \n",
       "2  2361    17     8       7  \n",
       "3  1380    14     5      14  \n",
       "4  3892     5     1       4  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bcd03963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#피처 스케일링\n",
    "\n",
    "test_ss = ss.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "520e63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = grid.predict(test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8b21c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_test_pred)\n",
    "y_pred.columns = ['target']\n",
    "y_pred['index'] = y_pred.index\n",
    "y_pred = y_pred[['index', 'target']]\n",
    "\n",
    "y_pred.to_csv(\"kaggle1.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a960235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
