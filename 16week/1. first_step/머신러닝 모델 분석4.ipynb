{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859e0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bb4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1058ea6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6599\n",
       "1     220\n",
       "Name: Bankrupt?, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Bankrupt?'].value_counts() #불균형 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831da297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X_res:  (13198, 95)\n",
      "the shape of y_res:  (13198,)\n",
      "counts of label 1:  6599\n",
      "counts of label 0:  6599\n"
     ]
    }
   ],
   "source": [
    "#over sampling - SMOTE\n",
    "\n",
    "from imblearn.over_sampling import *\n",
    "\n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n",
    "\n",
    "X_res, y_res = SMOTE(random_state=50).fit_resample(X,y)\n",
    "\n",
    "print('the shape of X_res: ', X_res.shape)\n",
    "print('the shape of y_res: ', y_res.shape)\n",
    "\n",
    "print('counts of label 1: ', sum(y_res==1))\n",
    "print('counts of label 0: ', sum(y_res==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5486233f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>Operating Gross Margin</th>\n",
       "      <th>Realized Sales Gross Margin</th>\n",
       "      <th>Operating Profit Rate</th>\n",
       "      <th>Pre-tax net Interest Rate</th>\n",
       "      <th>After-tax net Interest Rate</th>\n",
       "      <th>Non-industry income and expenditure/revenue</th>\n",
       "      <th>Continuous interest rate (after tax)</th>\n",
       "      <th>...</th>\n",
       "      <th>Net Income to Total Assets</th>\n",
       "      <th>Total assets to GNP price</th>\n",
       "      <th>No-credit Interval</th>\n",
       "      <th>Gross Profit to Sales</th>\n",
       "      <th>Net Income to Stockholder's Equity</th>\n",
       "      <th>Liability to Equity</th>\n",
       "      <th>Degree of Financial Leverage (DFL)</th>\n",
       "      <th>Interest Coverage Ratio (Interest expense to EBIT)</th>\n",
       "      <th>Net Income Flag</th>\n",
       "      <th>Equity to Liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.207936</td>\n",
       "      <td>-0.938720</td>\n",
       "      <td>-1.258199</td>\n",
       "      <td>-0.116670</td>\n",
       "      <td>-0.117637</td>\n",
       "      <td>0.024488</td>\n",
       "      <td>-0.007381</td>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.072419</td>\n",
       "      <td>-0.018256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.914078</td>\n",
       "      <td>-0.074778</td>\n",
       "      <td>-0.094828</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.126592</td>\n",
       "      <td>0.090532</td>\n",
       "      <td>-0.092783</td>\n",
       "      <td>-0.123352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.428297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.301795</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>0.451067</td>\n",
       "      <td>0.450975</td>\n",
       "      <td>0.022007</td>\n",
       "      <td>0.045342</td>\n",
       "      <td>0.045370</td>\n",
       "      <td>0.037382</td>\n",
       "      <td>0.038315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317506</td>\n",
       "      <td>-0.074778</td>\n",
       "      <td>-0.012923</td>\n",
       "      <td>0.451270</td>\n",
       "      <td>0.147421</td>\n",
       "      <td>-0.074470</td>\n",
       "      <td>16.550281</td>\n",
       "      <td>0.473038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.486625</td>\n",
       "      <td>-0.125374</td>\n",
       "      <td>-0.450401</td>\n",
       "      <td>-0.117136</td>\n",
       "      <td>-0.123706</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>-0.059112</td>\n",
       "      <td>-0.046687</td>\n",
       "      <td>-0.146173</td>\n",
       "      <td>-0.094343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006316</td>\n",
       "      <td>-0.074778</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>-0.117070</td>\n",
       "      <td>0.074943</td>\n",
       "      <td>0.090185</td>\n",
       "      <td>-0.095994</td>\n",
       "      <td>-0.156852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.428181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.827632</td>\n",
       "      <td>-0.645821</td>\n",
       "      <td>-0.627168</td>\n",
       "      <td>-1.275452</td>\n",
       "      <td>-1.278203</td>\n",
       "      <td>-0.004291</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557576</td>\n",
       "      <td>-0.074778</td>\n",
       "      <td>-0.089555</td>\n",
       "      <td>-1.275568</td>\n",
       "      <td>0.027822</td>\n",
       "      <td>-0.129631</td>\n",
       "      <td>-0.086069</td>\n",
       "      <td>-0.063633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.266647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.304172</td>\n",
       "      <td>0.156584</td>\n",
       "      <td>-0.289602</td>\n",
       "      <td>-0.290835</td>\n",
       "      <td>0.024908</td>\n",
       "      <td>0.043833</td>\n",
       "      <td>0.045672</td>\n",
       "      <td>0.027554</td>\n",
       "      <td>0.043099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313091</td>\n",
       "      <td>-0.074778</td>\n",
       "      <td>-0.026812</td>\n",
       "      <td>-0.289620</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>-0.212897</td>\n",
       "      <td>-0.222079</td>\n",
       "      <td>1.002910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.019062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROA(C) before interest and depreciation before interest  \\\n",
       "0                                          -1.207936          \n",
       "1                                           0.010306          \n",
       "2                                          -0.486625          \n",
       "3                                          -0.827632          \n",
       "4                                           0.019814          \n",
       "\n",
       "    ROA(A) before interest and % after tax  \\\n",
       "0                                -0.938720   \n",
       "1                                 0.301795   \n",
       "2                                -0.125374   \n",
       "3                                -0.645821   \n",
       "4                                 0.304172   \n",
       "\n",
       "    ROA(B) before interest and depreciation after tax  \\\n",
       "0                                          -1.258199    \n",
       "1                                           0.088997    \n",
       "2                                          -0.450401    \n",
       "3                                          -0.627168    \n",
       "4                                           0.156584    \n",
       "\n",
       "    Operating Gross Margin   Realized Sales Gross Margin  \\\n",
       "0                -0.116670                     -0.117637   \n",
       "1                 0.451067                      0.450975   \n",
       "2                -0.117136                     -0.123706   \n",
       "3                -1.275452                     -1.278203   \n",
       "4                -0.289602                     -0.290835   \n",
       "\n",
       "    Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
       "0                0.024488                   -0.007381   \n",
       "1                0.022007                    0.045342   \n",
       "2                0.012542                   -0.059112   \n",
       "3               -0.004291                    0.001155   \n",
       "4                0.024908                    0.043833   \n",
       "\n",
       "    After-tax net Interest Rate   Non-industry income and expenditure/revenue  \\\n",
       "0                     -0.004163                                     -0.072419   \n",
       "1                      0.045370                                      0.037382   \n",
       "2                     -0.046687                                     -0.146173   \n",
       "3                      0.011587                                      0.012418   \n",
       "4                      0.045672                                      0.027554   \n",
       "\n",
       "    Continuous interest rate (after tax)  ...   Net Income to Total Assets  \\\n",
       "0                              -0.018256  ...                    -0.914078   \n",
       "1                               0.038315  ...                     0.317506   \n",
       "2                              -0.094343  ...                    -0.006316   \n",
       "3                               0.009550  ...                    -0.557576   \n",
       "4                               0.043099  ...                     0.313091   \n",
       "\n",
       "    Total assets to GNP price   No-credit Interval   Gross Profit to Sales  \\\n",
       "0                   -0.074778            -0.094828               -0.116814   \n",
       "1                   -0.074778            -0.012923                0.451270   \n",
       "2                   -0.074778             0.007139               -0.117070   \n",
       "3                   -0.074778            -0.089555               -1.275568   \n",
       "4                   -0.074778            -0.026812               -0.289620   \n",
       "\n",
       "    Net Income to Stockholder's Equity   Liability to Equity  \\\n",
       "0                            -0.126592              0.090532   \n",
       "1                             0.147421             -0.074470   \n",
       "2                             0.074943              0.090185   \n",
       "3                             0.027822             -0.129631   \n",
       "4                             0.147500             -0.212897   \n",
       "\n",
       "    Degree of Financial Leverage (DFL)  \\\n",
       "0                            -0.092783   \n",
       "1                            16.550281   \n",
       "2                            -0.095994   \n",
       "3                            -0.086069   \n",
       "4                            -0.222079   \n",
       "\n",
       "    Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
       "0                                          -0.123352                 0.0   \n",
       "1                                           0.473038                 0.0   \n",
       "2                                          -0.156852                 0.0   \n",
       "3                                          -0.063633                 0.0   \n",
       "4                                           1.002910                 0.0   \n",
       "\n",
       "    Equity to Liability  \n",
       "0             -0.428297  \n",
       "1             -0.335235  \n",
       "2             -0.428181  \n",
       "3             -0.266647  \n",
       "4             -0.019062  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2) 피쳐 스케일링\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_sc = scaler.fit_transform(X_res)\n",
    "X_res_scaled = pd.DataFrame(X_sc, columns=X.columns)\n",
    "X_res_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "514340b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res_scaled, y_res, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b58452f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier():  0.9389\n",
      "LogisticRegression():  0.9000\n",
      "DecisionTreeClassifier():  0.9442\n",
      "GaussianNB():  0.6705\n",
      "RandomForestClassifier():  0.9747\n",
      "AdaBoostClassifier():  0.9321\n",
      "GradientBoostingClassifier():  0.9518\n",
      "[19:00:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None):  0.9826\n",
      "LGBMClassifier():  0.9818\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors  #KNN\n",
    "from sklearn.svm import SVC    #SVC\n",
    "from sklearn.linear_model import LogisticRegression  #LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier  #DecisionTree\n",
    "from sklearn.naive_bayes import GaussianNB   #가우시안\n",
    "from sklearn.ensemble import RandomForestClassifier #RandomForest\n",
    "from sklearn.ensemble import AdaBoostClassifier   #Adaboost\n",
    "from sklearn.ensemble import GradientBoostingClassifier   #GradientBoost\n",
    "from xgboost import XGBClassifier   #XGBoost\n",
    "from lightgbm import LGBMClassifier  #Light GBM\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "lr = LogisticRegression()\n",
    "tree = DecisionTreeClassifier()\n",
    "GNB = GaussianNB()\n",
    "rf = RandomForestClassifier()\n",
    "ada = AdaBoostClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "xgb = XGBClassifier()\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "for model in [knn, lr, tree, GNB, rf, ada, gb, xgb, lgbm]:\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_model = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred_model)\n",
    "    \n",
    "    print('{0}: {1: .4f}'.format(model, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16854db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.9641697337085949\n"
     ]
    }
   ],
   "source": [
    "#1) Randomforest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_estimators':[100],\n",
    "         'min_samples_leaf':[1,2,4],\n",
    "         'min_samples_split':[2,4,8]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_rf = GridSearchCV(rf, param_grid=params, cv=2)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_rf.best_params_)\n",
    "print(grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1167a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.9753, 정밀도:  0.9564, 재현율:  0.9954, f1 score:  0.9755 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "pred_rf = grid_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_rf)\n",
    "precision = precision_score(y_test, pred_rf)\n",
    "recall = recall_score(y_test, pred_rf)\n",
    "f1 = f1_score(y_test, pred_rf)\n",
    "                          \n",
    "print('정확도: {0: .4f}, 정밀도: {1: .4f}, 재현율: {2: .4f}, f1 score: {3: .4f} '.format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a464e0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:17:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:17:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:18:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:18:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:18:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:18:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:18:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:18:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:18:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 500}\n",
      "0.9768348127300281\n"
     ]
    }
   ],
   "source": [
    "#2) XGBoost\n",
    "\n",
    "params = {'n_estimators':[500],\n",
    "         'learning_rate':[0.1, 0.3,0.5],\n",
    "         'max_depth':[4,6,8]}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "grid_xgb = GridSearchCV(xgb, param_grid=params, cv=2)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(grid_xgb.best_params_)\n",
    "print(grid_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61c6f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.9841, 정밀도:  0.9707, 재현율:  0.9980, f1 score:  0.9842 \n"
     ]
    }
   ],
   "source": [
    "pred_xgb = grid_xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_xgb)\n",
    "precision = precision_score(y_test, pred_xgb)\n",
    "recall = recall_score(y_test, pred_xgb)\n",
    "f1 = f1_score(y_test, pred_xgb)\n",
    "                          \n",
    "print('정확도: {0: .4f}, 정밀도: {1: .4f}, 재현율: {2: .4f}, f1 score: {3: .4f} '.format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a37ee407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.3, max_depth=6, n_estimators=500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2) LGBM\n",
    "\n",
    "grid_lgbm = LGBMClassifier(learning_rate=0.3, max_depth=6, n_estimators=500)\n",
    "grid_lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "018948b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.9902, 정밀도:  0.9805, 재현율:  1.0000, f1 score:  0.9902 \n"
     ]
    }
   ],
   "source": [
    "pred_lgbm = grid_lgbm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_lgbm)\n",
    "precision = precision_score(y_test, pred_lgbm)\n",
    "recall = recall_score(y_test, pred_lgbm)\n",
    "f1 = f1_score(y_test, pred_lgbm)\n",
    "      \n",
    "print('정확도: {0: .4f}, 정밀도: {1: .4f}, 재현율: {2: .4f}, f1 score: {3: .4f} '.format(accuracy, precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
